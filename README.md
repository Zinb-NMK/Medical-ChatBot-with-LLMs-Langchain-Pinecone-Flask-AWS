# ğŸ©º Build a Complete Medical Chatbot using LLMs, LangChain, Pinecone & Flask

This project is a **Retrieval-Augmented Generation (RAG) based Medical Chatbot** built using **LangChain**, **Pinecone**, **Flask**, and **Hugging Face LLMs (FLAN-T5)**.

The chatbot allows users to ask **medical-related questions**, retrieves relevant context from indexed medical documents stored in Pinecone, and generates **concise, factual answers** using a local Hugging Face model.

---

## ğŸ“˜ Documentation Status

> âš ï¸ **Note:** This README is currently undergoing **minor updates** to improve clarity, structure, and accuracy.

âœ”ï¸ **Project Functionality:** Complete & Stable  
ğŸ› ï¸ **Documentation:** Small refinements in progress  
ğŸš€ **Application Status:** Fully operational  

---

### ğŸ” Purpose of Update
â€¢ Improve readability and formatting  
â€¢ Reflect recent enhancements  
â€¢ Align with industry documentation standards  

---

### â³ Current Status Summary
ğŸ”¹ Codebase: **Finalized**  
ğŸ”¹ Backend & Frontend: **Working as expected**  
ğŸ”¹ Documentation: **Being polished**  

---

ğŸ™ Thank you for your patience.

----

## ğŸš€ Features

- Medical Question Answering using **RAG architecture**
- Semantic search with **Pinecone Vector Database**
- Local **Hugging Face FLAN-T5** model (no OpenAI dependency)
- Flask-based web interface
- Handles spelling mistakes and vague queries
- Prevents repetitive or hallucinated answers
- Lightweight and CPU-friendly setup

---

## ğŸ§  Architecture Overview

1. Medical documents are converted into embeddings
2. Embeddings are stored in **Pinecone**
3. User question is embedded and matched against stored vectors
4. Relevant context is retrieved
5. LLM generates an answer **only using retrieved context**

---

## ğŸ› ï¸ Tech Stack Used

- Python 3.10
- LangChain
- Pinecone
- Flask
- Hugging Face Transformers (FLAN-T5)
- HTML, CSS (Frontend)

---

## ğŸ“‚ Project Structure

```text
â”œâ”€â”€ app.py                  # Flask application
â”œâ”€â”€ store_index.py          # Stores document embeddings in Pinecone
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py           # PDF loading & embeddings
â”‚   â””â”€â”€ prompt.py           # System prompt
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ chat.html           # Frontend UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css           # UI styling
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


### âš™ï¸ How to Run the Project

**STEP 01: Clone the Repository**
git clone https://github.com/Zinb-NMK/Medical-ChatBot-with-LLMs-Langchain-Pinecone-Flask-AWS.git  
cd Medical-ChatBot-with-LLMs-Langchain-Pinecone-Flask-AWS

**STEP 02: Create and Activate Conda Environment**
conda create -n medibot python=3.10 -y  
conda activate medibot

**STEP 03: Install Requirements**
pip install -r requirements.txt

**STEP 04: Setup Environment Variables**
Create a `.env` file in the root directory:
PINECONE_API_KEY=your_pinecone_api_key_here

**STEP 05: Store Embeddings in Pinecone**
python store_index.py  
(Loads medical documents â†’ Creates embeddings â†’ Stores in Pinecone)

**STEP 06: Run the Flask Application**
python app.py

**STEP 07: Open the Application**
http://127.0.0.1:5000

---

### ğŸ§ª Example Questions
â€¢ What is diabetes?  
â€¢ What are the causes of fever?  
â€¢ Cough medications and prevention tips  
â€¢ What is acne?

---

### âš ï¸ Important Notes
â€¢ Educational purpose only  
â€¢ No medical diagnosis  
â€¢ Always consult healthcare professionals  

---

### ğŸ§¹ Git Best Practices
â€¢ Large files ignored using `.gitignore`  
â€¢ Avoid `git add .`  
Use:
git add app.py src/ templates/ static/ .gitignore README.md

---

### ğŸ“Œ Future Enhancements
â€¢ Conversation memory  
â€¢ Source citations  
â€¢ Improved medical coverage  
â€¢ Cloud deployment (AWS / Render)

---

### ğŸ‘¤ Author
Nagaram Manoj Kumar  
Aspiring AI/ML Engineer | Medical AI Enthusiast

â­ If you like this project, give it a star!
